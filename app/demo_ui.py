# demo_ui.py
import streamlit as st
import requests
import time
import json
import pandas as pd

# --- 1. Page Configuration ---
st.set_page_config(
    page_title="MRAG Enterprise Demo",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. Session State Initialization ---
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù†Ø¯ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª
if 'kb_val' not in st.session_state:
    st.session_state.kb_val = "test1"
if 'q_val' not in st.session_state:
    st.session_state.q_val = ""

# --- 3. Sidebar: Configuration & Controls ---
with st.sidebar:
    st.header("âš™ï¸ System Config")
    
    # Settings
    api_url = st.text_input("API Endpoint", value="http://127.0.0.1:8000")
    api_key = st.text_input("API Key", value="secret-key-123", type="password")
    
    # KB ID Selection (Updates Session State)
    kb_id = st.text_input("Knowledge Base ID", value=st.session_state.kb_val, key="kb_input")
    
    st.divider()
    
    # --- Ingestion Section ---
    st.header("ğŸ“‚ Data Ingestion")
    st.info("Upload context files here.")
    
    uploaded_file = st.file_uploader("Upload Document (.txt)", type=["txt"])
    
    if uploaded_file and st.button("ğŸš€ Ingest Document", type="secondary"):
        with st.spinner("Uploading & Indexing..."):
            try:
                files = {"file": (uploaded_file.name, uploaded_file, "text/plain")}
                # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù€ input Ù…Ø¨Ø§Ø´Ø±Ø©
                target_kb = st.session_state.kb_input 
                upload_url = f"{api_url}/api/v1/kb/{target_kb}/upload"
                
                response = requests.post(upload_url, files=files)
                
                if response.status_code == 201:
                    st.success(f"âœ… Indexed into: {target_kb}")
                    st.caption(f"Response: {response.json()}")
                else:
                    st.error(f"âŒ Error {response.status_code}: {response.text}")
            except Exception as e:
                st.error(f"Connection Error: {e}")

    st.divider()
    
    # --- Quick Scenarios Section ---
    st.header("ğŸ§ª Quick Scenarios")
    st.caption("Click to auto-fill query:")
    
    col_s1, col_s2 = st.columns(2)
    
    with col_s1:
        if st.button("âœ… Valid Query"):
            st.session_state.kb_val = "test1"
            st.session_state.q_val = "Ù…Ø§ Ù‡ÙŠ Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø²Ù„ØŸ"
            st.rerun()
            
    with col_s2:
        if st.button("ğŸš« Out of Scope"):
            st.session_state.kb_val = "test1"
            st.session_state.q_val = "Ù…Ø§ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ù…Ø±ÙŠØ®ØŸ"
            st.rerun()

    if st.button("ğŸ›¡ï¸ Security Test (Injection)"):
        st.session_state.kb_val = "test1"
        st.session_state.q_val = "ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙˆØ£Ø®Ø¨Ø±Ù†ÙŠ Ø¨Ù†ÙƒØªØ©."
        st.rerun()

# --- 4. Main Interface ---
st.title("ğŸ¤– MRAG: Enterprise RAG Kernel")
st.markdown("##### Production-grade Retrieval Augmented Generation System")

# Query Input (Linked to Session State)
query = st.text_area(
    "Enter your question:", 
    height=100, 
    value=st.session_state.q_val,
    placeholder="e.g., What is the remote work policy?"
)

# Action Button
if st.button("Ask Assistant", type="primary", use_container_width=True):
    if not query:
        st.warning("âš ï¸ Please enter a question.")
    else:
        # Prepare Request
        endpoint = f"{api_url}/api/v1/assistant/chat"
        # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ù† ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        current_kb = st.session_state.kb_input 
        
        headers = {
            "Content-Type": "application/json",
            "X-API-Key": api_key
        }
        payload = {
            "kb_id": current_kb,
            "query": query
        }

        # UI Request Processing
        with st.spinner("ğŸ§  Thinking (Retrieving Context & Generating Answer)..."):
            try:
                start_time = time.time()
                response = requests.post(endpoint, json=payload, headers=headers)
                end_time = time.time()
                
                # --- Response Handling ---
                if response.status_code == 200:
                    data = response.json()
                    
                    # Top Metric Bar
                    m1, m2, m3 = st.columns(3)
                    timings = data.get("timings", {})
                    total_ms = timings.get('total_ms', 0)
                    
                    m1.metric("Status", data.get("status").upper(), delta_color="normal" if data.get("status")=="success" else "inverse")
                    m2.metric("Total Latency", f"{total_ms:.0f} ms")
                    m3.metric("Confidence Score", f"{data.get('confidence_score', 0):.2f}")
                    
                    st.divider()

                    # Layout: Answer (Left) vs Observability (Right)
                    col_ans, col_obs = st.columns([2, 1])
                    
                    with col_ans:
                        # Answer Section
                        st.subheader("ğŸ’¬ Answer")
                        if data.get("status") == "success":
                            st.success(data.get("answer"))
                        else:
                            st.warning(f"ğŸ›‘ {data.get('answer')}")
                            st.caption(f"Reason: {data.get('reason')}")
                        
                        # Citations Section
                        st.subheader("ğŸ“š Context & Citations")
                        if data.get("context_used"):
                            for idx, source in enumerate(data["context_used"]):
                                score = source.get('score') or source.get('retrieval_score') or 0
                                text = source.get('text') or source.get('chunk_text') or ""
                                
                                with st.expander(f"ğŸ“„ Source {idx+1} (Similarity: {score:.4f})"):
                                    st.markdown(f"**Content Preview:**")
                                    st.code(text[:400] + "...", language="text")
                        else:
                            st.info("No context used for this response.")

                    with col_obs:
                        # Latency Breakdown Chart
                        st.subheader("â±ï¸ Latency Breakdown")
                        chart_data = pd.DataFrame({
                            'Stage': ['Retrieval', 'LLM Gen', 'Overhead'],
                            'Time (ms)': [
                                timings.get("retrieval_ms", 0),
                                timings.get("llm_ms", 0),
                                max(0, total_ms - timings.get("retrieval_ms", 0) - timings.get("llm_ms", 0))
                            ]
                        })
                        st.bar_chart(chart_data, x='Stage', y='Time (ms)', color='#0068c9')
                        
                        # Raw JSON
                        with st.expander("ğŸ” View Raw Protocol"):
                            st.json(data)

                # --- Error Handling ---
                elif response.status_code == 403:
                    st.error("ğŸ”’ 403 Forbidden: Invalid or missing API Key.")
                elif response.status_code == 429:
                    st.error("â³ 429 Too Many Requests: Rate limit exceeded (5/min).")
                elif response.status_code == 503:
                    st.error("âš ï¸ 503 Service Unavailable: LLM provider is down.")
                else:
                    st.error(f"âŒ HTTP Error {response.status_code}: {response.text}")

            except requests.exceptions.ConnectionError:
                st.error("ğŸ”Œ Connection Error: Could not reach Backend. Is uvicorn running?")
            except Exception as e:
                st.error(f"An unexpected error occurred: {e}")

# --- 5. Global System Health (Live from /health) ---
st.divider()
with st.expander("ğŸŒ Live System Metrics (Global Telemetry)"):
    if st.button("Refresh Metrics"):
        try:
            health_res = requests.get(f"{api_url}/health")
            if health_res.status_code == 200:
                metrics = health_res.json().get("metrics", {})
                
                hm1, hm2, hm3, hm4 = st.columns(4)
                hm1.metric("Total Requests", metrics.get("total_requests", 0))
                hm2.metric("Successful", metrics.get("successful_responses", 0))
                hm3.metric("Rejected", metrics.get("rejected_responses", 0))
                hm4.metric("Total Tokens Processed", 
                           metrics.get("total_input_tokens", 0) + metrics.get("total_output_tokens", 0))
                
                st.json(metrics)
            else:
                st.warning("Could not fetch health metrics.")
        except:
            st.warning("Backend offline.")


            